/**
 * Copyright 2013-2016 Felix Schmitt, Heiko Burau, Rene Widera
 *
 * This file is part of libPMacc.
 *
 * libPMacc is free software: you can redistribute it and/or modify
 * it under the terms of either the GNU General Public License or
 * the GNU Lesser General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * libPMacc is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License and the GNU Lesser General Public License
 * for more details.
 *
 * You should have received a copy of the GNU General Public License
 * and the GNU Lesser General Public License along with libPMacc.
 * If not, see <http://www.gnu.org/licenses/>.
 */

#include "pmacc_types.hpp"
#include "particles/memory/boxes/ParticlesBox.hpp"
#include "particles/memory/boxes/PushDataBox.hpp"
#include "particles/memory/boxes/TileDataBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "mappings/kernel/ExchangeMapping.hpp"
#include "particles/memory/boxes/ExchangePushDataBox.hpp"
#include "particles/memory/boxes/ExchangePopDataBox.hpp"

#include "particles/operations/Assign.hpp"
#include "particles/operations/Deselect.hpp"
#include "traits/NumberOfExchanges.hpp"
#include "nvidia/atomic.hpp"

#include "mappings/elements/Vectorize.hpp"
#include "memory/dataTypes/Array.hpp"

#include <mutex>

namespace PMacc
{

template<typename T_ParticleBox, typename T_SuperCellIdxType>
DINLINE typename T_ParticleBox::FramePtr
getPreviousFrameAndRemoveLastFrame( const typename T_ParticleBox::FramePtr& frame,
                                    T_ParticleBox& pb,
                                    const T_SuperCellIdxType& superCellIdx )
{
    typename T_ParticleBox::FramePtr result = pb.getPreviousFrame( frame );
    pb.removeLastFrame( superCellIdx );
    return result;
}

/*! This kernel move particles to the next supercell
 * This kernel can only run with a double checker board
 */
template< int T_elemSize = 1 >
struct kernelShiftParticles
{
template<class T_ParBox, class Mapping, typename T_Acc>
DINLINE void operator()( const T_Acc& acc, T_ParBox pb, Mapping mapper ) const
{
    namespace mapElem = mappings::elements;

    typedef T_ParBox ParBox;
    typedef typename ParBox::FrameType FrameType;
    typedef typename ParBox::FramePtr FramePtr;
    typedef typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type FramePtrShared;

    const uint32_t dim = Mapping::Dim;
    const uint32_t frameSize = math::CT::volume<typename FrameType::SuperCellSize>::type::value;
    /* number exchanges in 2D=9 and in 3D=27 */
    const uint32_t numExchanges = traits::NumberOfExchanges<dim>::value;

    /* define memory for two times Exchanges
     * index range [0,numExchanges-1] are being referred to as `low frames`
     * index range [numExchanges,2*numExchanges-1] are being referred to as `high frames`
     */
    sharedMem(destFrames, cupla::Array<FramePtrShared,numExchanges * 2>);
    sharedMem(destFramesCounter, cupla::Array<int,numExchanges>); //count particles per frame


    sharedMem(frame, FramePtrShared);
    sharedMem(mustShift, bool);

    DataSpace<dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<dim> (blockIdx) );

    const int stridedLinearThreadIdx = threadIdx.x * T_elemSize;

    if ( stridedLinearThreadIdx == 0 )
    {
        mustShift = pb.getSuperCell( superCellIdx ).mustShift( );
        if ( mustShift )
        {
            pb.getSuperCell( superCellIdx ).setMustShift( false );
            frame = pb.getFirstFrame( superCellIdx );
        }
    }

    __syncthreads( );
    if ( !mustShift || !frame.isValid( ) ) return;

    /* lastFrameSize is only valid for threads with `linearThreadIdx` < numExchanges */
    cupla::Array<uint32_t, T_elemSize> lastFrameSizeArray;
    cupla::Array<DataSpace<dim>, T_elemSize> relativeArray;

    mapElem::vectorize<DIM1>(
        [&]( const int idx )
        {
            const int linearThreadIdx = stridedLinearThreadIdx + idx;
            lastFrameSizeArray[idx] = 0;
            relativeArray[idx] = superCellIdx + Mask::getRelativeDirections<dim> (linearThreadIdx + 1);

            /* if a partially filled last frame exists for the neighboring supercell,
             * each master thread (one master per direction) will load it
             */
            if ( linearThreadIdx < numExchanges )
            {
                destFramesCounter[linearThreadIdx] = 0;
                destFrames[linearThreadIdx] = FramePtr();
                destFrames[linearThreadIdx + numExchanges] = FramePtr();
                /* load last frame of neighboring supercell */
                FramePtrShared tmpFrame(pb.getLastFrame( relativeArray[idx] ));

                if ( tmpFrame.isValid() )
                {
                    lastFrameSizeArray[idx] = pb.getSuperCell( relativeArray[idx] ).getSizeLastFrame( );
                    // do not use the neighbor's last frame if it is full
                    if ( lastFrameSizeArray[idx] < frameSize )
                    {
                        destFrames[linearThreadIdx] = tmpFrame;
                        destFramesCounter[linearThreadIdx] = lastFrameSizeArray[idx];
                    }
                }
            }
        },
        T_elemSize
    );
    __syncthreads( );

    cupla::Array<lcellId_t, T_elemSize> destParticleIdxArray;
    cupla::Array<int, T_elemSize> directionArray;

    /* iterate over the frame list of the current supercell */
    while ( frame.isValid() )
    {
        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                destParticleIdxArray[idx] = INV_LOC_IDX;
                const int linearThreadIdx = stridedLinearThreadIdx + idx;

                /* set to value to of multiMask to a value in range [-2, EXCHANGES - 1]
                 * -2 is no particle
                 * -1 is particle but it is not shifted (stays in supercell)
                 * >=0 particle moves in a certain direction
                 *     (@see ExchangeType in types.h)
                 */
                directionArray[idx] = frame[linearThreadIdx][multiMask_] - 2;
                if ( directionArray[idx] >= 0 )
                {
                    destParticleIdxArray[idx] = atomicAdd( &(destFramesCounter[ directionArray[idx] ]), 1 , ::alpaka::hierarchy::Threads() );
                }
            },
            T_elemSize
        );
        __syncthreads( );
        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int linearThreadIdx = stridedLinearThreadIdx + idx;
                /* If the master thread (responsible for a certain direction) did not
                 * obtain a `low frame` from the neighboring super cell before the loop,
                 * it will create one now.
                 *
                 * In case not all particles that are shifted to the neighboring
                 * supercell fit into the `low frame`, a second frame is created to
                 * contain further particles, the `high frame` (default: invalid).
                 */
                if ( linearThreadIdx < numExchanges )
                {
                    if ( destFramesCounter[linearThreadIdx] > 0 )
                    {
                        lastFrameSizeArray[idx] = destFramesCounter[linearThreadIdx];
                        /* if we had no `low frame` we load a new empty one */
                        if ( !destFrames[linearThreadIdx].isValid() )
                        {
                            FramePtrShared tmpFrame(pb.getEmptyFrame( ));
                            destFrames[linearThreadIdx] = tmpFrame;
                            pb.setAsLastFrame( acc, tmpFrame, relativeArray[idx] );
                        }
                        /* check if a `high frame` is needed */
                        if ( destFramesCounter[linearThreadIdx] > frameSize )
                        {
                                lastFrameSizeArray[idx] = destFramesCounter[linearThreadIdx] - frameSize;
                                FramePtrShared tmpFrame(pb.getEmptyFrame( ));
                                destFrames[linearThreadIdx + numExchanges] = tmpFrame;
                                pb.setAsLastFrame( acc, tmpFrame, relativeArray[idx] );
                        }
                    }
                }
            },
            T_elemSize
        );
        __syncthreads( );

        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int linearThreadIdx = stridedLinearThreadIdx + idx;
                /* All threads with a valid index in the neighbor's frame, valid index
                 * range is [0, frameSize * 2-1], will copy their particle to the new
                 * frame.
                 *
                 * The default value for indexes (in the destination frame) is
                 * above this range (INV_LOC_IDX) for all particles that are not shifted.
                 */
                if ( destParticleIdxArray[idx] < frameSize * 2 )
                {
                    if ( destParticleIdxArray[idx] >= frameSize )
                    {
                        /* use `high frame` */
                        directionArray[idx] += numExchanges;
                        destParticleIdxArray[idx] -= frameSize;
                    }
                    PMACC_AUTO( dstParticle, destFrames[ directionArray[idx] ][ destParticleIdxArray[idx] ] );
                    PMACC_AUTO( srcParticle, frame[linearThreadIdx] );
                    dstParticle[multiMask_] = 1;
                    srcParticle[multiMask_] = 0;
                    PMACC_AUTO( dstFilteredParticle,
                                particles::operations::deselect<multiMask>(dstParticle) );
                    particles::operations::assign( dstFilteredParticle, srcParticle );
                }
            },
            T_elemSize
        );
        __syncthreads( );

        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int linearThreadIdx = stridedLinearThreadIdx + idx;
                /* if the `low frame` is now full, each master thread removes it and
                 * uses the `high frame` (is invalid, if still empty) as the next
                 * `low frame` for the following iteration of the loop
                 */
                if ( linearThreadIdx < numExchanges )
                {
                    if ( destFramesCounter[linearThreadIdx] >= frameSize )
                    {
                        destFramesCounter[linearThreadIdx] -= frameSize;
                        destFrames[linearThreadIdx] = destFrames[linearThreadIdx + numExchanges];
                        destFrames[linearThreadIdx + numExchanges] = FramePtr();
                    }
                }
            },
            T_elemSize
        );
        if ( stridedLinearThreadIdx == 0 )
        {
            frame = pb.getNextFrame( frame );
        }
        __syncthreads( );
    }

    mapElem::vectorize<DIM1>(
        [&]( const int idx )
        {
            const int linearThreadIdx = stridedLinearThreadIdx + idx;
            /* each master thread updates the number of particles in the last frame
             * of the neighbors supercell
             */
            if ( linearThreadIdx < numExchanges )
            {
                pb.getSuperCell( relativeArray[idx] ).setSizeLastFrame( lastFrameSizeArray[idx] );
            }
        },
        T_elemSize
    );
}
};

template<int T_elemSize = 1>
struct kernelFillGapsLastFrame
{
template<class ParBox, class Mapping, typename T_Acc>
DINLINE void operator()( const T_Acc& acc, ParBox pb, Mapping mapper ) const
{
    using namespace particles::operations;
    namespace mapElem = mappings::elements;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    typedef typename ParBox::FramePtr FramePtr;

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) );

    sharedMem(lastFrame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);

    sharedMem(gapIndices_sh, cupla::Array<int,TileSize>);
    sharedMem(counterGaps, int);
    sharedMem(counterParticles, int);

    sharedMem(srcGap, int);

    const int stridedLinearThreadIdx = threadIdx.x * T_elemSize;

    if ( stridedLinearThreadIdx == 0 )
    {
        lastFrame = pb.getLastFrame( DataSpace<Dim > (superCellIdx) );
        counterGaps = 0;
        counterParticles = 0;
        srcGap = 0;
    }
    __syncthreads( );

    cupla::Array<bool,T_elemSize> isParticleArray;

    if ( lastFrame.isValid( ) )
    {
        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int threadIndex = stridedLinearThreadIdx + idx;
                //count particles in last frame
                isParticleArray[idx] = lastFrame[threadIndex][multiMask_];
                if ( isParticleArray[idx] == true ) //\todo: bits z√§hlen
                {
                    nvidia::atomicAllInc( acc, &counterParticles, ::alpaka::hierarchy::Threads() );
                }
            },
            T_elemSize
        );
        __syncthreads( );

        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int threadIndex = stridedLinearThreadIdx + idx;
                if ( threadIndex < counterParticles && isParticleArray[idx] == false )
                {
                    const int localGapIdx = nvidia::atomicAllInc( acc, &counterGaps, ::alpaka::hierarchy::Threads() );
                    gapIndices_sh[localGapIdx] = threadIndex;
                }
            },
            T_elemSize
        );
        __syncthreads( );
        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int threadIndex = stridedLinearThreadIdx + idx;
                if ( threadIndex >= counterParticles && isParticleArray[idx] )
                {
                    //any particle search a gap
                    const int srcGapIdx = nvidia::atomicAllInc( acc, &srcGap, ::alpaka::hierarchy::Threads() );
                    const int gapIdx = gapIndices_sh[srcGapIdx];
                    PMACC_AUTO( parDestFull, lastFrame[gapIdx] );
                    /*enable particle*/
                    parDestFull[multiMask_] = 1;
                    /* we not update multiMask because copy from mem to mem is to slow
                     * we have enabled particle explicit */
                    PMACC_AUTO( parDest, deselect<multiMask>(parDestFull) );
                    PMACC_AUTO( parSrc, (lastFrame[threadIndex]) );
                    assign( parDest, parSrc );
                    parSrc[multiMask_] = 0; //delete old partice
                }
            },
            T_elemSize
        );
    }
    if ( stridedLinearThreadIdx == 0 )
        pb.getSuperCell( superCellIdx ).setSizeLastFrame( counterParticles );

}
};

template<int T_elemSize = 1>
struct kernelFillGaps
{
template<class ParBox, class Mapping, typename T_Acc>
DINLINE void operator()( const T_Acc& acc, ParBox pb, Mapping mapper ) const
{
    using namespace particles::operations;
    namespace mapElem = mappings::elements;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    typedef typename ParBox::FramePtr FramePtr;

    DataSpace<Dim> superCellIdx( mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) ) );

    //data copied from right (last) to left (first)
    sharedMem(firstFrame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);
    sharedMem(lastFrame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);

    sharedMem(particleIndices_sh, cupla::Array<int,TileSize>);
    sharedMem(counterGaps, int);
    sharedMem(counterParticles, int);

    const int stridedLinearThreadIdx = threadIdx.x * T_elemSize;

    if ( stridedLinearThreadIdx == 0 )
    {
        firstFrame = pb.getFirstFrame( DataSpace<Dim > (superCellIdx) );
        lastFrame = pb.getLastFrame( DataSpace<Dim > (superCellIdx) );
    }
    __syncthreads( );

    cupla::Array<int,T_elemSize> localGapIdxArray;

    while ( firstFrame.isValid( ) && firstFrame != lastFrame )
    {

        if ( stridedLinearThreadIdx == 0 )
        {
            //\todo: check if we need control thread or can write to shared with all threads
            counterGaps = 0;
            counterParticles = 0;
        }
        __syncthreads( );

        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                localGapIdxArray[idx] = INV_LOC_IDX; //later we cann call localGapIdx < X because X<INV_LOC_IDX
                const int threadIndex = stridedLinearThreadIdx + idx;
                // find gaps
                if ( firstFrame[threadIndex][multiMask_] == 0 )
                {
                    localGapIdxArray[idx] = nvidia::atomicAllInc( acc, &counterGaps, ::alpaka::hierarchy::Threads() );
                }
            },
            T_elemSize
        );
        __syncthreads( );

        if ( counterGaps == 0 )
        {
            if ( stridedLinearThreadIdx == 0 )
            {
                firstFrame = pb.getNextFrame( firstFrame );
            }
            __syncthreads( ); //wait control thread search new frame
            continue; //check next frame
        }

        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int threadIndex = stridedLinearThreadIdx + idx;
                // search particles for gaps
                if ( lastFrame[threadIndex][multiMask_] == 1 )
                {
                    int localParticleIdx = nvidia::atomicAllInc( acc, &counterParticles, ::alpaka::hierarchy::Threads() );
                    particleIndices_sh[localParticleIdx] = threadIndex;
                }
            },
            T_elemSize
        );
        __syncthreads( );
        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int threadIndex = stridedLinearThreadIdx + idx;
                if ( localGapIdxArray[idx] < counterParticles )
                {
                    const int parIdx = particleIndices_sh[localGapIdxArray[idx]];
                    PMACC_AUTO( parDestFull, (firstFrame[threadIndex]) );
                    /*enable particle*/
                    parDestFull[multiMask_] = 1;
                    /* we not update multiMask because copy from mem to mem is to slow
                     * we have enabled particle explicit */
                    PMACC_AUTO( parDest, deselect<multiMask>(parDestFull) );
                    PMACC_AUTO( parSrc, (lastFrame[parIdx]) );
                    assign( parDest, parSrc );
                    parSrc[multiMask_] = 0;
                }
            },
            T_elemSize
        );
        __syncthreads( );

        if ( stridedLinearThreadIdx == 0 )
        {
            if ( counterGaps < counterParticles )
            {
                //any gap in the first frame is filled
                firstFrame = pb.getNextFrame( firstFrame );
            }
            else if ( counterGaps > counterParticles )
            {
                //we need more particles
                lastFrame = getPreviousFrameAndRemoveLastFrame( lastFrame, pb, superCellIdx );
            }
            else if ( counterGaps == counterParticles )
            {
                lastFrame = getPreviousFrameAndRemoveLastFrame( lastFrame, pb, superCellIdx );
                if ( lastFrame.isValid( ) && lastFrame != firstFrame )
                {
                    firstFrame = pb.getNextFrame( firstFrame );
                }
            }
        }
        __syncthreads( );
    }
}
};

template<int T_elemSize = 1>
struct kernelDeleteParticles
{
template< class T_ParticleBox, class Mapping, typename T_Acc>
DINLINE void operator()( const T_Acc& acc,
                                       T_ParticleBox pb,
                                       Mapping mapper ) const
{
    using namespace particles::operations;
    namespace mapElem = mappings::elements;

    typedef T_ParticleBox ParticleBox;
    typedef typename ParticleBox::FrameType FrameType;
    typedef typename ParticleBox::FramePtr FramePtr;

    enum
    {
        Dim = Mapping::Dim
    };

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) );
    const int stridedLinearThreadIdx = threadIdx.x * T_elemSize;

    sharedMem(frame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);

    if ( stridedLinearThreadIdx == 0 )
    {
        frame = pb.getLastFrame( superCellIdx );
    }

    __syncthreads( );

    while ( frame.isValid( ) )
    {

        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                const int linearThreadIdx = stridedLinearThreadIdx + idx;
                PMACC_AUTO( particle, (frame[linearThreadIdx]) );
                particle[multiMask_] = 0; //delete particle
            },
            T_elemSize
        );

        __syncthreads( );

        if ( stridedLinearThreadIdx == 0 )
        {
            //always remove the last frame
            frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
        }
        __syncthreads( );
    }

    if ( stridedLinearThreadIdx == 0 )
        pb.getSuperCell( superCellIdx ).setSizeLastFrame( 0 );

}
};

template< int T_elemSize = 1 >
struct kernelBashParticles
{
template< class ParBox, class BORDER, class Mapping, typename T_Acc>
DINLINE void operator()( const T_Acc& acc, ParBox pb,
                                     ExchangePushDataBox<vint_t, BORDER, Mapping::Dim - 1 > border,
                                     Mapping mapper ) const
{
    using namespace particles::operations;
    namespace mapElem = mappings::elements;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };
    typedef typename ParBox::FramePtr FramePtr;

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex( DataSpace<Dim > (blockIdx) );
    const int stridedLinearThreadIdx = threadIdx.x * T_elemSize;

    sharedMem(numBashedParticles, int);
    sharedMem(frame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);
    sharedMem(hasMemory, bool);
    sharedMem(tmpBorder, TileDataBox<BORDER>);

    if ( stridedLinearThreadIdx == 0 )
    {
        hasMemory = true;
        frame = pb.getLastFrame( superCellIdx );
    }
    //\todo: eventuell ist es schneller, parallelen und seriellen Code zu trennen
    __syncthreads( );
    cupla::Array<lcellId_t,T_elemSize> bashIdxArray;

    while ( frame.isValid( ) && hasMemory )
    {

        if ( stridedLinearThreadIdx == 0 )
            numBashedParticles = 0;
        __syncthreads( );
        mapElem::vectorize<DIM1>(
            [&]( const int idx )
            {
                bashIdxArray[idx] = INV_LOC_IDX;
                const int linearThreadIdx = stridedLinearThreadIdx + idx;
                if ( frame[linearThreadIdx][multiMask_] == 1 )
                {
                    bashIdxArray[idx] = nvidia::atomicAllInc( acc, &numBashedParticles, ::alpaka::hierarchy::Threads() );
                }
            },
            T_elemSize
        );
        __syncthreads( );

        if ( numBashedParticles > 0 )
        {
            if ( stridedLinearThreadIdx == 0 )
            {
                // DataSpaceOperations<DIM2>::reduce computes target position for domainTile and exchangeType
                tmpBorder = border.pushN( acc,  numBashedParticles,
                                          DataSpaceOperations<Dim>::reduce(
                                                                            superCellIdx,
                                                                            mapper.getExchangeType( ) ) );
                if ( tmpBorder.getSize( ) < numBashedParticles )
                    hasMemory = false;
            }
            __syncthreads( );
            mapElem::vectorize<DIM1>(
                [&]( const int idx )
                {
                    const int linearThreadIdx = stridedLinearThreadIdx + idx;
                    if ( bashIdxArray[idx] != INV_LOC_IDX && bashIdxArray[idx] < tmpBorder.getSize( ) )
                    {
                        PMACC_AUTO( parDest, tmpBorder[ bashIdxArray[idx] ][0] );
                        PMACC_AUTO( parSrc, (frame[linearThreadIdx]) );
                        assign( parDest, parSrc );
                        parSrc[multiMask_] = 0;
                    }
                },
                T_elemSize
            );
            __syncthreads( );

            if ( stridedLinearThreadIdx == 0 && hasMemory )
            {
                //always remove the last frame
                frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
            }

        }
        else
        {
            //if we had no particles to copy than we are the last and only frame
            if ( stridedLinearThreadIdx == 0 )
            {
                frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
            }
        }
        __syncthreads( );
    }
    if ( stridedLinearThreadIdx == 0 )
        pb.getSuperCell( superCellIdx ).setSizeLastFrame( 0 );

}
};


template< int T_elemSize = 1 >
struct kernelInsertParticles
{
template<class ParBox, class BORDER, class Mapping, typename T_Acc>
DINLINE void operator()( const T_Acc& acc, ParBox pb,
                                       ExchangePopDataBox<vint_t, BORDER, Mapping::Dim - 1 > border,
                                       Mapping mapper ) const
{

    using namespace particles::operations;
    namespace mapElem = mappings::elements;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    typedef typename ParBox::FramePtr FramePtr;
    sharedMem(frame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);
    sharedMem(elementCount, int);
    sharedMem(tmpBorder, TileDataBox<BORDER>);

    const int stridedLinearThreadIdx = threadIdx.x * T_elemSize;

    DataSpace < Mapping::Dim - 1 > superCell;

    if ( stridedLinearThreadIdx == 0 )
    {
        tmpBorder = border.get(blockIdx.x,superCell);
        elementCount = tmpBorder.getSize( );
        if ( elementCount > 0 )
        {
            frame = pb.getEmptyFrame( );
        }
    }
    __syncthreads( );
    mapElem::vectorize<DIM1>(
        [&]( const int idx )
        {
            const int linearThreadIdx = stridedLinearThreadIdx + idx;
            if ( linearThreadIdx < elementCount )
            {
                PMACC_AUTO( parDestFull, (frame[linearThreadIdx]) );
                parDestFull[multiMask_] = 1;
                PMACC_AUTO( parSrc, ((tmpBorder[linearThreadIdx])[0]) );
                /*we know that source has no multiMask*/
                PMACC_AUTO( parDest, deselect<multiMask>(parDestFull) );
                assign( parDest, parSrc );
            }
        },
        T_elemSize
    );
    /*if this syncronize fix the kernel crash in spezial cases,
     * I can't tell why.
     */
    __syncthreads( );
    if ( (stridedLinearThreadIdx == 0) && (elementCount > 0) )
    {
        // compute the super cell position in target frame to insert into
        ///\todo: offset == simulation border should be passed to this func instead of being created here
        DataSpace<Dim> dstSuperCell = DataSpaceOperations < Dim - 1 > ::extend( superCell,
                                                                                mapper.getExchangeType( ),
                                                                                mapper.getGridSuperCells( ),
                                                                                DataSpace<Dim>::create( mapper.getGuardingSuperCells( ) ) );


        pb.setAsLastFrame( acc, frame, dstSuperCell );

    }


}
};



} //namespace PMacc
