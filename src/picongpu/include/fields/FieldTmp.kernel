/**
 * Copyright 2013-2016 Axel Huebl, Rene Widera, Marco Garten
 *
 * This file is part of PIConGPU.
 *
 * PIConGPU is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * PIConGPU is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with PIConGPU.
 * If not, see <http://www.gnu.org/licenses/>.
 */



#pragma once

#include "pmacc_types.hpp"
#include "particles/frame_types.hpp"

#include "simulation_defines.hpp"

#include "FieldTmp.hpp"
#include "particles/memory/boxes/ParticlesBox.hpp"

#include "memory/boxes/CachedBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "nvidia/functors/Add.hpp"
#include "mappings/threads/ThreadCollective.hpp"
#include "algorithms/Set.hpp"

#include "particles/frame_types.hpp"

namespace picongpu
{
    using namespace PMacc;

    template<
        class BlockDescription_,
        uint32_t AREA,
        typename T_ElemSize = typename PMacc::math::CT::make_Int<simDim,1>::type::vector_type
    >
    struct kernelComputeSupercells
    {
    template< class TmpBox, class ParBox, class FrameSolver, class Mapping, typename T_Acc>
    DINLINE void operator()( const T_Acc& acc,  TmpBox fieldTmp, ParBox boxPar, FrameSolver frameSolver, Mapping mapper ) const
    {
        namespace mapElem = mappings::elements;

        typedef typename ParBox::FramePtr FramePtr;
        typedef typename BlockDescription_::SuperCellSize SuperCellSize;
        const DataSpace<simDim> block( mapper.getSuperCellIndex( DataSpace<simDim > ( blockIdx ) ) );

        const DataSpace<simDim > stridedThreadIndex( DataSpace<simDim >(threadIdx) * T_ElemSize::toRT() );

        /* thread id, can be greater than cellsPerSuperCell*/
        const int stridedLinearThreadIdx = DataSpaceOperations<simDim>::template map<SuperCellSize > (stridedThreadIndex);

        sharedMem(frame, typename PMacc::traits::GetEmptyDefaultConstructibleType<FramePtr>::type);

        sharedMem(particlesInSuperCell, lcellId_t);


        if( stridedLinearThreadIdx == 0 )
        {
            frame = boxPar.getLastFrame( block );
            particlesInSuperCell = boxPar.getSuperCell( block ).getSizeLastFrame( );
        }
        __syncthreads( );

        if( !frame.isValid() )
            return; //end kernel if we have no frames

        PMACC_AUTO( cachedVal, CachedBox::create < 0, typename TmpBox::ValueType > ( acc, BlockDescription_( ) ) );
        Set<typename TmpBox::ValueType > set( float_X( 0.0 ) );

        constexpr int stride = PMacc::math::CT::volume<SuperCellSize>::type::value / PMacc::math::CT::volume<T_ElemSize>::type::value;

        ThreadCollective<BlockDescription_, stride> collective( stridedThreadIndex );
        collective( set, cachedVal );

        __syncthreads( );
        while( frame.isValid() )
        {
            mapElem::vectorize<simDim>(
                [&]( const DataSpace<simDim>& idx )
                {
                    DataSpace<simDim> threadIndex( stridedThreadIndex + idx );
                    const int linearThreadIdx = DataSpaceOperations<simDim>::template map<SuperCellSize > ( threadIndex );
                    if( linearThreadIdx < particlesInSuperCell )
                    {
                        frameSolver( acc, *frame, linearThreadIdx, SuperCellSize::toRT(), cachedVal );
                    }
                },
                T_ElemSize::toRT()
            );
            __syncthreads( );

            if( stridedLinearThreadIdx == 0 )
            {
                frame = boxPar.getPreviousFrame( frame );
                particlesInSuperCell = PMacc::math::CT::volume<SuperCellSize>::type::value;
            }
            __syncthreads( );
        }

        nvidia::functors::Add add;
        const DataSpace<simDim> blockCell = block * MappingDesc::SuperCellSize::toRT( );
        PMACC_AUTO( fieldTmpBlock, fieldTmp.shift( blockCell ) );
        collective( add, fieldTmpBlock, cachedVal );
        __syncthreads( );
    }
    };

    template<typename T_ElemSize = typename PMacc::math::CT::make_Int<simDim,1>::type::vector_type >
    struct kernelBashValue
    {
    template<class Box, class Mapping, typename T_Acc>
    DINLINE void operator()( const T_Acc& acc,
                                     Box fieldTmp,
                                     Box targetJ,
                                     DataSpace<simDim> exchangeSize,
                                     DataSpace<simDim> direction,
                                     Mapping mapper ) const
    {
        namespace mapElem = mappings::elements;
        const DataSpace<simDim> blockCell(
                                           mapper.getSuperCellIndex( DataSpace<simDim > ( blockIdx ) )
                                           * Mapping::SuperCellSize::toRT( )
                                           );
        const DataSpace<simDim> stridedThreadIndex( DataSpace<simDim >(threadIdx) * T_ElemSize::toRT() );

        mapElem::vectorize<simDim>(
            [&]( const DataSpace<simDim>& idx )
            {
                const DataSpace<simDim> threadIndex( stridedThreadIndex + idx );
                const DataSpace<Mapping::Dim> sourceCell( blockCell + threadIndex );

                /*origin in area from local GPU*/
                DataSpace<simDim> nullSourceCell(
                                                  mapper.getSuperCellIndex( DataSpace<simDim > ( ) )
                                                  * Mapping::SuperCellSize::toRT( )
                                                  );
                DataSpace<simDim> targetCell( sourceCell - nullSourceCell );

                for (uint32_t d = 0; d < simDim; ++d)
                {
                    if( direction[d] == -1 )
                    {
                        if( threadIndex[d] < SuperCellSize::toRT()[d] - exchangeSize[d] ) return;
                        targetCell[d] -= SuperCellSize::toRT()[d] - exchangeSize[d];
                    }
                    else if( ( direction[d] == 1 ) && ( threadIndex[d] >= exchangeSize[d] ) ) return;
                }
                targetJ( targetCell ) = fieldTmp( sourceCell );
            },
            T_ElemSize::toRT()
        );
    }
    };

    template<typename T_ElemSize = typename PMacc::math::CT::make_Int<simDim,1>::type::vector_type >
    struct kernelInsertValue
    {
    template<class Box, class Mapping, typename T_Acc>
    DINLINE void operator()( const T_Acc& acc,
                                       Box fieldTmp,
                                       Box sourceTmp,
                                       DataSpace<simDim> exchangeSize,
                                       DataSpace<simDim> direction,
                                       Mapping mapper ) const
    {
        namespace mapElem = mappings::elements;
        const DataSpace<simDim> blockCell(
                                           mapper.getSuperCellIndex( DataSpace<simDim > ( blockIdx ) )
                                           * Mapping::SuperCellSize::toRT( )
                                           );
        const DataSpace<simDim> stridedThreadIndex( DataSpace<simDim >(threadIdx) * T_ElemSize::toRT() );

        mapElem::vectorize<simDim>(
            [&]( const DataSpace<simDim>& idx )
            {
                const DataSpace<simDim> threadIndex( stridedThreadIndex + idx );
                DataSpace<Mapping::Dim> targetCell(blockCell + threadIndex);

                /*origin in area from local GPU*/
                DataSpace<simDim> nullSourceCell(
                                                  mapper.getSuperCellIndex( DataSpace<simDim > ( ) )
                                                  * Mapping::SuperCellSize::toRT( )
                                                  );
                DataSpace<simDim> sourceCell( targetCell - nullSourceCell );

                for (uint32_t d = 0; d < simDim; ++d)
                {
                    if( direction[d] == 1 )
                    {
                        if( threadIndex[d] < SuperCellSize::toRT()[d] - exchangeSize[d] ) return;
                        sourceCell[d] -= SuperCellSize::toRT()[d] - exchangeSize[d];
                        targetCell[d] -= SuperCellSize::toRT()[d];
                    }
                    else if( direction[d] == -1 )
                    {
                        if( threadIndex[d] >= exchangeSize[d] ) return;
                        targetCell[d] += SuperCellSize::toRT()[d];
                    }
                }

            fieldTmp( targetCell ) += sourceTmp( sourceCell );
            },
            T_ElemSize::toRT()
        );
    }
    };

} // namespace picongpu
